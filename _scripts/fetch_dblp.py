#!/usr/bin/env python3
import requests
import xml.etree.ElementTree as ET
import yaml
import os

dblp_ids = [
    "150/6416",  # JÃ¼rgen Cito
]

OUTPUT_FILE = "_data/publications/dblp_generated.yml"

def text(elem, tag):
    t = elem.find(tag)
    return t.text.strip() if t is not None and t.text else ""

def normalize_title(title):
    """Normalize title for comparison by removing trailing punctuation and converting to lowercase."""
    return title.rstrip('.').lower()

def get_publication_priority(pub):
    """
    Return a priority score for deduplication.
    Lower scores are preferred (kept over higher scores).
    
    Priority order:
    1. Published conference/journal papers (inproceedings, article in non-CoRR venues)
    2. CoRR preprints (article in CoRR)
    3. Other types
    
    Within each category, prefer newer publications.
    """
    if pub["type"] == "inproceedings":
        return (0, -(pub["year"] or 0))
    elif pub["type"] == "article" and pub["venue"] != "CoRR":
        return (1, -(pub["year"] or 0))
    elif pub["type"] == "article" and pub["venue"] == "CoRR":
        return (2, -(pub["year"] or 0))
    else:
        return (3, -(pub["year"] or 0))

publications = []

for pid in dblp_ids:
    url = f"https://dblp.org/pid/{pid}.xml"
    print(f"Fetching DBLP data for {pid}...")
    resp = requests.get(url, timeout=10)
    if resp.status_code != 200:
        continue

    root = ET.fromstring(resp.text)

    for r in root.findall("r"):
        entry = list(r)[0]
        key = entry.attrib.get("key")
        if not key:
            continue

        # Extract DOI or other direct links from ee elements
        ee_elements = entry.findall("ee")
        url = f"https://dblp.org/rec/{key}"  # default to dblp
        if ee_elements:
            # Prefer DOI links, then any other link
            for ee in ee_elements:
                if ee.text:
                    url = ee.text
                    break

        pub = {
            "id": key,
            "title": text(entry, "title"),
            "year": int(text(entry, "year")) if text(entry, "year").isdigit() else None,
            "venue": text(entry, "journal") or text(entry, "booktitle"),
            "type": entry.tag,
            "authors": [a.text for a in entry.findall("author") if a.text],
            "url": url
        }

        publications.append(pub)

# Deduplicate by normalized title, keeping the highest priority version
from collections import defaultdict
title_groups = defaultdict(list)
for pub in publications:
    normalized = normalize_title(pub["title"])
    title_groups[normalized].append(pub)

deduplicated = []
for normalized_title, pubs in title_groups.items():
    if len(pubs) == 1:
        deduplicated.append(pubs[0])
    else:
        # Sort by priority and keep the best one
        pubs.sort(key=get_publication_priority)
        best = pubs[0]
        deduplicated.append(best)
        
        # Log duplicates being removed
        if len(pubs) > 1:
            print(f"  Deduplicating '{best['title']}':")
            print(f"    Keeping: {best['type']} in {best['venue']} ({best['year']})")
            for dup in pubs[1:]:
                print(f"    Removing: {dup['type']} in {dup['venue']} ({dup['year']})")

publications = deduplicated

# Sort: newest first, then title
publications.sort(
    key=lambda p: (-(p["year"] or 0), p["title"])
)

os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    f.write("# This file is auto-generated by scripts/fetch_dblp.py. Do not edit manually.\n")
    yaml.dump(publications, f, allow_unicode=True)

print(f"Generated {OUTPUT_FILE} with {len(publications)} publications.")
